# 分布式系统

[MIT 6.824: Distributed Systems](https://pdos.csail.mit.edu/6.824/index.html)

## 第1章 分布式系统介绍

### 基本概念

分布式系统（Distributed Systems）：采用计算机集群来解决问题

分布式系统通常比单机解决问题的方式更复杂，采用分布式系统的原因有：

- **并行化**：提高性能
- **容错率**：多个节点，防止其中一个崩溃造成系统性问题
- **物理要求**：如距离较远的服务器之间通信
- **安全性**：孤立多台计算机保证信息安全

然而，**concurrency**、**partial failure**、**performance**也常是分布式系统的应用难点



labs:

1. MapReduce
2. Raft算法
3. 运用Raft算法的KV服务器
4. 分片式KV服务器



分布式基础设施：

- 存储storage
- 计算computation
- 通信communication



**RPC**，remote procedure call，远程过程调用：目的是为了掩盖在不可靠网络上通信的事实



容错性（Fault Tolerance）：

- 可用性（Availability）
- 可恢复性（Recoverability）
- 持久化（NV storage）
- 复制（Replication）



**一致性**（consistency）问题

- 强一致性系统：保证每次请求一定能得到最新的值。通常需要更高的通信成本
- 弱一致性系统：不保证请求能得到最新的值





### MapReduce

论文链接：[MapReduce (2004)](https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf)

MapReduce是一种编程模式，包含Map功能和Reduce功能

外部调用Map(file, value) ---> emit(k, v) ---> Reduce(k, v) ---> emit(len(v))



#### Lab1: MapReduce

[6.824 Lab 1: MapReduce](https://pdos.csail.mit.edu/6.824/labs/lab-mr.html)



设计思路：

- 生产者-消费者模式
- coordinator一次性生产n个map任务，由多个worker通过rpc来取
- n个map任务全部完成后coordinator再一次性生产m个reduce任务
- 设计Task类，包含id、type等属性，用来表示具体的任务
  - 使用缓冲容量为n的channel存放map的task
  - 使用缓冲容量为m的channel存放reduce的task
- 设计TaskMetaInfo类表示任务元信息，用来记录task指针和状态、开始时间，由MetaHolder保存在分别对应map和reduce的两个指针切片中
  - 状态有三种：WAITING、RUNNING、DONE，分别表示未分配、已分配未完成、已完成
  - MetaHolder在每次worker请求task或汇报完成task时，扫描切片并修改状态
  - coordinator初始化后启动一个goroutine用于定时检查任务是否完成，其中需要MetaHolder扫描切片的任务状态
  - coordinator包含一个 `sync.Mutex` 互斥锁，用来保证请求task和扫描元信息切片时的**并发安全**
- 设计一个channel，在定时检查到全部任务结束后用来保证此时前来请求任务的worker能与coordinator基本在**同一时间退出**
- 利用 `ioutil.TempFile()` 实现map和reduce输出文件时，所有临时文件写完后再重命名，若此间进程意外崩溃则写出的文件不可用
- 利用一个goroutine实现定时对所有worker的**任务超时检测**，此时利用到MetaHolder里元信息记录的起始时间和当前时间进行推算，对于超时的task则重新设置状态为WAITING



tips：官方的测试脚本test-mr.sh需要使用bash 4.3及以上的版本运行，否则低版本的不支持 `wait -n` 的指令会报错，无法通过"early exit test"





### RPC与多线程

这门课使用Go的原因：

- 多线程优势
- 强大而遍历的RPC库
- 内存安全





### GFS

论文链接：[The Google File System (2003)](https://pdos.csail.mit.edu/6.824/papers/gfs.pdf)

[GFS论文中文翻译版](https://developer.aliyun.com/article/586529)

[GFS论文要点总结](https://blog.csdn.net/yuyixinye/article/details/43483139?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165148078416782388045568%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&request_id=165148078416782388045568&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-1-43483139.142^v9^pc_search_result_cache,157^v4^control&utm_term=The+Google+File+System&spm=1018.2226.3001.4187)



构建分布式存储的矛盾：

追求大型存储的**性能** ---> 采用分片（sharding）构建分布式存储

大型分布式系统更容易产生错误 ---> 需求**容错性**

高**容错性**要求 ---> 大规模的**复制**

大规模**复制** ---> **一致性**要求

**一致性**的要求 ---> 低性能



Google对文件系统的设计要求：

- 规模大：经常又单个文件比单个磁盘大的情况
- 速度快：请求量极大
- 通用：在不同集群上能迁移
- 分片：分布式，高吞吐量
- 自动化错误恢复机制：高容错性和自动化的修复
- 大文件的**顺序读取**



Google的经典分布式存储系统里，通常有上百个客服机（client），1个master，数百个块服务器（chunkserver）

- 每个块（chunk）为64MB

  这样设计的目的：

  - 减小master的传输负担

- master的需要保存：

  - 文件名到chunk句柄的映射 nv
  - chunkserver的列表 v
  - 版本列表，包含每个chunk的版本 nv
  - 主chunk v
  - 租约（lease）过期时间 v

- master持久化一个操作记录**日志**和若干个**检查点**（快照，每个花费几十秒到几分钟）

- 通常有1个主chunkserver，2个备用chunkserver

- 读流程：

  1. client发送：文件名 + 偏移量 ---> master
  2. master发送

- master的故障切换需要人工操作





### 主从复制

论文链接：[The Design of a Practical System for Fault-Tolerant Virtual Machines](https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf)



主从复制用于解决fail-stop错误（如断电、过热、内核错误等），而不是软件中的bug或硬件本身的设计缺陷



主从复制的两种方案：

- 状态转移：备机与主机同步，带宽要求高
- 复制状态机：同步操作（类似Redis的AOF），不同服务器上的状态机执行日志中相同顺序的相同操作，因此保证了一致性

VMware的论文中采用第二种策略，只同步确定性（deterministic）的指令，非确定性（non-deterministic）的，如获取local time，只让主机执行，备机监听主机的结果

主从之间采用logging channel进行通信





### Raft

论文链接：[Raft](https://raft.github.io/raft.pdf)

[Raft Github首页](https://raft.github.io/)

[一个Raft算法的可视化](http://thesecretlivesofdata.com/raft/)

